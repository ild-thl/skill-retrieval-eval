{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain_core.documents import Document\n",
    "from typing import Dict, List, Set, Optional, Any, Tuple\n",
    "import json\n",
    "import requests\n",
    "from api_client import APIClient\n",
    "from api_config import APIConfig\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup evaluation data\n",
    "\n",
    "Only execute one of the following cells to either setup a GRETA or ESCO evalution dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup for GRETA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfile = 'evalGretaModelResults.json'\n",
    "\n",
    "# load greata csv file to pandas dataframe GRETA-Kompetenzmodell_v2.csv\n",
    "greta_pd = pd.read_csv('./data/GRETA/sources/GRETA-Kompetenzmodell_v2.csv', sep=';', encoding='utf-8')\n",
    "\n",
    "# Create new column that combines the columns \"Kompetenzfacetten\", \"Kompetenzaspekte\", \"Kompetenzbereiche\", \"Kompetenzanforderungen\", \"Kompetenzbeschreibung\"\n",
    "# greta_pd['page_content'] = \"Kompetenz: \" + greta_pd['Kompetenzfacette'] + '/n gehÃ¶rt zu /n Kompetenzaspekt: ' + greta_pd['Kompetenzaspekt'] + ', Kompetenzbereich: ' + greta_pd['Kompetenzbereich'] + ',/n Kompetenzanforderungen: ' + greta_pd['Kompetenzanforderungen'] + ', Kompetenzbeschreibung: ' + greta_pd['Kompetenzbeschreibung']\n",
    "greta_pd['page_content'] = greta_pd['Kompetenzfacette'] + ',/nKompetenzanforderungen: ' + greta_pd['Kompetenzanforderungen']\n",
    "# Only get page_content and Kompetenzfacette columns\n",
    "greta_pd = greta_pd[['page_content', 'Kompetenzfacette']]\n",
    "# Rename Kompetenzfacette to title\n",
    "greta_pd = greta_pd.rename(columns={'Kompetenzfacette': 'title'})\n",
    "\n",
    "# Get the evaluation data\n",
    "with open('./data/GRETA/validated_greta_240704.json', 'r', encoding='utf-8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "\n",
    "# Load the data into the DataFrameLoader\n",
    "loader = DataFrameLoader(greta_pd, page_content_column=\"page_content\")\n",
    "documents = loader.load()\n",
    "corpus = {i: d['title'] for i, d in enumerate(greta_pd.to_dict('records'))}\n",
    "queries = {i: d['query'] for i, d in enumerate(data)}\n",
    "\n",
    "relevant_docs = {}\n",
    "for i, d in enumerate(data):\n",
    "    relevant_docs[i] = []\n",
    "    for doc in d['pos']:\n",
    "        for j, c in corpus.items():\n",
    "            if c == doc:\n",
    "                relevant_docs[i].append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup for ESCO Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfile = 'results/evalESCOModelResults.json'\n",
    "\n",
    "# Load texts from json file\n",
    "skills = pd.read_csv(\"./data/ESCO/sources/skills_as_documents_v120.csv\")\n",
    "\n",
    "skills['description'] = skills['description'].fillna('')\n",
    "skills['broaderHierarchyConcepts'] = skills['broaderHierarchyConcepts'].fillna('')\n",
    "skills['broaderSkills'] = skills['broaderSkills'].fillna('')\n",
    "skills['narrowerSkills'] = skills['narrowerSkills'].fillna('')\n",
    "skills['isEssentialForOccupations'] = skills['isEssentialForOccupations'].fillna('')\n",
    "skills['isOptionalForOccupations'] = skills['isOptionalForOccupations'].fillna('')\n",
    "skills['isEssentialForSkills'] = skills['isEssentialForSkills'].fillna('')\n",
    "skills['isOptionalForSkills'] = skills['isOptionalForSkills'].fillna('')\n",
    "\n",
    "# Create a new column that combines preferredLabel and description.\n",
    "skills['page_content'] = skills['preferredLabel'] + \" \\n \" + skills['description']\n",
    "\n",
    "# Add a new column called 'taxonomy' with the value 'ESCO'.\n",
    "skills['taxonomy'] = 'ESCO'\n",
    "\n",
    "# remove row where page_content or title is empty\n",
    "skills = skills[skills['page_content'].notna()]\n",
    "skills = skills[skills['preferredLabel'].notna()]\n",
    "\n",
    "skills = skills[['page_content', 'preferredLabel']]\n",
    "# Are there rows with missing preferredLabel?\n",
    "# Rename Kompetenzfacette to title\n",
    "skills = skills.rename(columns={'preferredLabel': 'title'})\n",
    "\n",
    "# Get the evaluation data\n",
    "import json\n",
    "with open('./data/ESCO/wisy_validated_240704.json', 'r', encoding='utf-8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "\n",
    "# Load  the documents\n",
    "loader = DataFrameLoader(skills, page_content_column=\"page_content\")\n",
    "documents = loader.load()\n",
    "corpus = {i: d['title'] for i, d in enumerate(skills.to_dict('records'))}\n",
    "queries = {i: d['query'] for i, d in enumerate(data)}\n",
    "# relevant_docs = {i: [corpus.index(doc) for doc in d['pos']] for i, d in enumerate(data)}\n",
    "relevant_docs = {}\n",
    "for i, d in enumerate(data):\n",
    "    relevant_docs[i] = []\n",
    "    for doc in d['pos']:\n",
    "        for j, c in corpus.items():\n",
    "            if c == doc:\n",
    "                relevant_docs[i].append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Retrieval Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pasca\\code\\ISy\\WISY@KI\\skill-retrieval-eval\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from retrieval_evaluator import RetrievalEvaluator\n",
    "evaluator = RetrievalEvaluator(queries, corpus, relevant_docs, store_docs=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIConfig for evaluating skill prediction APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom formatters for different APIs\n",
    "\n",
    "def competence_analyser_request_formatter(query: str, top_k: int) -> Tuple[Dict, Optional[Dict]]:\n",
    "    \"\"\"\n",
    "    Format request for the competence analyser API v2/chatsearch endpoint\n",
    "    Returns (data, params) tuple\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"doc\": query,  # The course description goes into 'doc' field\n",
    "        \"taxonomies\": [\"ESCO\"],  # Focus on ESCO taxonomy for our evaluation\n",
    "        \"targets\": [\"learning_outcomes\"],  # We want learning outcomes\n",
    "        \"top_k\": top_k,\n",
    "        \"rerank\": True,  # Use reranking\n",
    "        \"finetuned\": True,  # Use fine-tuned models\n",
    "        \"trusted_score\": 0.0,  # Accept all scores, we'll filter later\n",
    "        \"score_cutoff\": 0.0,  # Accept all scores\n",
    "        \"strict\": 0,  # Get all top_k offers, without any cutoff\n",
    "        \"use_llm\": False,  # Don't use LLM extraction to keep it comparable\n",
    "        \"openai_api_key\": os.getenv(\"OPENAI_API_KEY\", \"\"),  # Use environment variable for OpenAI key\n",
    "        \"llm_validation\": False,  # Don't use LLM validation to keep it comparable\n",
    "    }\n",
    "    return data, None  # No URL parameters needed\n",
    "\n",
    "def competence_analyser_response_parser(response) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Parse response from the competence analyser API v2/chatsearch endpoint\n",
    "    Returns list of (skill_name, score) tuples\n",
    "    \"\"\"\n",
    "    result = response.json()\n",
    "    predictions = []\n",
    "    \n",
    "    # The v2 API returns a more complex structure\n",
    "    # We need to extract skills from learning_outcomes -> skills\n",
    "    if \"learning_outcomes\" in result and result[\"learning_outcomes\"]:\n",
    "        learning_outcomes = result[\"learning_outcomes\"]\n",
    "        if \"skills\" in learning_outcomes:\n",
    "            for skill in learning_outcomes[\"skills\"]:\n",
    "                if \"title\" in skill and \"score\" in skill:\n",
    "                    # Note: Higher scores are better in this API\n",
    "                    predictions.append((skill[\"title\"], float(skill[\"score\"])))\n",
    "    \n",
    "    # Sort by score descending (higher is better)\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return predictions\n",
    "\n",
    "def generic_api_request_formatter(query: str, top_k: int) -> Tuple[Dict, Optional[Dict]]:\n",
    "    \"\"\"Generic formatter for simple APIs\"\"\"\n",
    "    data = {\"query\": query, \"top_k\": top_k}\n",
    "    return data, None\n",
    "\n",
    "def generic_api_response_parser(response) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Generic parser for simple API responses\"\"\"\n",
    "    result = response.json()\n",
    "    predictions = []\n",
    "\n",
    "def metadatagen_request_formatter(query: str, top_k: int) -> Tuple[Dict, Optional[Dict]]:\n",
    "    \"\"\"Format request for the MetadataGen API\"\"\"\n",
    "    data = {\n",
    "        \"name\": query,  # Use course name as the query\n",
    "        \"description\": \"This course covers the fundamentals of machine learning including supervised and unsupervised learning algorithms, neural networks, and practical applications in data science.\",\n",
    "        \"top_k\": top_k  # Limit results to top_k skills\n",
    "    }\n",
    "\n",
    "    return data, None  # No URL parameters needed\n",
    "\n",
    "def get_esco_skill_name(skill_uri: str, language: str = 'en', version: str = 'v1.2.0') -> str:\n",
    "    \"\"\"Fetch the ESCO skill name based on the skill ID and language\"\"\"\n",
    "    # https://ec.europa.eu/esco/api/resource/skill?uri=&language=\n",
    "    url = f\"https://ec.europa.eu/esco/api/resource/skill?uri={skill_uri}&language={language}&selectedVersion={version}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result[\"preferredLabel\"][language] if \"preferredLabel\" in result and language in result[\"preferredLabel\"] else null\n",
    "    else:\n",
    "        print(f\"Error fetching skill name for {skill_uri}: {response.status_code} {response.text}\")\n",
    "        return null\n",
    "\n",
    "\n",
    "def metadatagen_response_parser(response) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Parse response from the MetadataGen API\"\"\"\n",
    "    result = response.json()\n",
    "    predictions = []\n",
    "    # The MetadataGen API returns a list of skills with concept URLs and names\n",
    "    if isinstance(result, list):\n",
    "        for index, item in enumerate(result):\n",
    "            if isinstance(item, dict) and \"name\" in item and \"conceptUrl\" in item:\n",
    "                skill_uri = item[\"conceptUrl\"]\n",
    "                # Here we assume descending scores based on index\n",
    "                score = 1.0 - (index / len(result))  # Normalize score to [0, 1]\n",
    "                de_skill_name = get_esco_skill_name(skill_uri, 'de', 'v1.2.0')\n",
    "                predictions.append((de_skill_name, score))\n",
    "            else:\n",
    "                # Handle unexpected item format\n",
    "                print(\"Unexpected item format in response:\", item)\n",
    "                continue\n",
    "    else:\n",
    "        # If the response is not a list, handle it gracefully\n",
    "        print(\"Unexpected response format:\", result)\n",
    "        return []\n",
    "    \n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)  # Sort by score descending\n",
    "    return predictions\n",
    "    \n",
    "    # Try different common response formats\n",
    "    if \"predictions\" in result:\n",
    "        for item in result[\"predictions\"]:\n",
    "            if isinstance(item, dict) and \"skill\" in item and \"score\" in item:\n",
    "                predictions.append((item[\"skill\"], float(item[\"score\"])))\n",
    "            elif isinstance(item, dict) and \"name\" in item and \"score\" in item:\n",
    "                predictions.append((item[\"name\"], float(item[\"score\"])))\n",
    "    elif \"skills\" in result and \"scores\" in result:\n",
    "        skills = result[\"skills\"]\n",
    "        scores = result[\"scores\"]\n",
    "        predictions = [(skill, float(score)) for skill, score in zip(skills, scores)]\n",
    "    elif isinstance(result, list):\n",
    "        for item in result:\n",
    "            if isinstance(item, dict):\n",
    "                if \"skill\" in item and \"score\" in item:\n",
    "                    predictions.append((item[\"skill\"], float(item[\"score\"])))\n",
    "                elif \"name\" in item and \"score\" in item:\n",
    "                    predictions.append((item[\"name\"], float(item[\"score\"])))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# API Configuration Examples\n",
    "# Customize these configurations based on your actual APIs\n",
    "\n",
    "# Your competence analyser API configuration\n",
    "COMPETENCE_ANALYSER_CONFIG = APIConfig(\n",
    "    name=\"competence_analyser\",\n",
    "    base_url=\"https://lab.dlc.sh/competence-analyser\",\n",
    "    endpoint=\"/v2/chatsearch\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    auth_token=None,  # Add your token if needed\n",
    "    request_format=\"json\",\n",
    "    response_format=\"json\",\n",
    "    max_requests_per_second=2.0,  # Be respectful to the API\n",
    "    timeout=60.0,  # Longer timeout for complex processing\n",
    "    custom_request_formatter=competence_analyser_request_formatter,\n",
    "    custom_response_parser=competence_analyser_response_parser\n",
    ")\n",
    "\n",
    "# MetadataGen API configuration\n",
    "METADATAGEN_API_CONFIG = APIConfig(\n",
    "    name=\"metadataGen\",\n",
    "    base_url=\"http://host.docker.internal\",\n",
    "    endpoint=\"/get_esco_suggestions\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    auth_token=None,  # Add their token if needed\n",
    "    request_format=\"json\",\n",
    "    response_format=\"json\",\n",
    "    max_requests_per_second=2.0,  # Be respectful to external APIs\n",
    "    timeout=45.0,\n",
    "    custom_request_formatter=metadatagen_request_formatter,\n",
    "    custom_response_parser=metadatagen_response_parser\n",
    ")\n",
    "\n",
    "# Additional API configurations can be added here\n",
    "API_CONFIGS = {\n",
    "    \"competence_analyser\": COMPETENCE_ANALYSER_CONFIG,\n",
    "    \"metadata_gen\": METADATAGEN_API_CONFIG,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresults = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresults[\"isy-finetuned\"] = evaluator(\"isy-thl/multilingual-e5-base-course-skill-tuned\", use_cached_db=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DB = True # Use same vectorstore from previous run, because the embedding model did not change\n",
    "modelresults[\"isy-finetuned-w-reranker\"] = evaluator(\"isy-thl/multilingual-e5-base-course-skill-tuned\", reranker_model_name=\"isy-thl/bge-reranker-base-course-skill-tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DB = False # Build new vectorstore\n",
    "modelresults[\"all-MiniLM-L6-v2\"] = evaluator(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelresults[\"bge_base\"] = evaluator(\"BAAI/bge-base-en-v1.5\")\n",
    "# modelresults[\"bge_finetuned\"] = evaluator(\"bge_finetuned_no_sync\")\n",
    "# modelresults[\"bge_greta_finetuned\"] = evaluator(\"bge_greta_finetuned_no_sync\")\n",
    "# modelresults[\"bge_m3\"] = evaluator(\"BAAI/bge-m3\")\n",
    "# modelresults[\"bge_m3_greta_finetuned\"] = evaluator(\"bge_m3_greta_finetuned_no_sync\")\n",
    "# modelresults[\"bge_m3_finetuned\"] = evaluator(\"bge_m3_finetuned_no_sync\")\n",
    "# modelresults[\"snowflake-arctic-embed-l\"] = evaluator(\"Snowflake/snowflake-arctic-embed-l\")\n",
    "# modelresults[\"multilingual-e5-base\"] = evaluator(\"intfloat/multilingual-e5-base\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_e5_greta_finetuned\"] = evaluator(\"multilingual_e5_greta_finetuned_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_e5_finetuned\"] = evaluator(\"multilingual_e5_finetuned_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_e5_m3_finetuned\"] = evaluator(\"multilingual_e5_m3_finetuned_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_finetuned_esco6000\"] = evaluator(\"multilingual_finetuned_esco6000_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_finetuned_esco1500\"] = evaluator(\"multilingual_finetuned_esco1500_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"mixed_multilingual_finetuned\"] = evaluator(\"mixed_multilingual_finetuned_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"bge_reranker_finetuned\"] = evaluator(\"multilingual_e5_finetuned_no_sync\", reranker_model_name=\"bge_reranker_finetuned_no_sync\")\n",
    "# modelresults[\"bge_reranker_greta_finetuned\"] = evaluator(\"multilingual_e5_finetuned_no_sync\", reranker_model_name=\"bge_reranker_greta_finetuned_no_sync\", use_cached_db=True)\n",
    "# modelresults[\"bge_reranker_skillfit\"] = evaluator(\"multilingual_e5_finetuned_no_sync\", reranker_model_name=\"pascalhuerten/bge_reranker_skillfit\", use_cached_db=True)\n",
    "# modelresults[\"instructor-base\"] = evaluator(\"hkunlp/instructor-base\", use_cached_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Testing Section\n",
    "\n",
    "Now we can test APIs alongside the embedding models. Configure your API endpoints above and run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API connectivity before running full evaluation\n",
    "def test_api_connectivity(api_config: APIConfig, test_query: str = \"Python programming\"):\n",
    "    \"\"\"Test if an API is accessible and returns valid responses\"\"\"\n",
    "    try:\n",
    "        client = APIClient(api_config)\n",
    "        predictions = client.predict(test_query, top_k=5)\n",
    "        \n",
    "        print(f\"â API '{api_config.name}' is accessible\")\n",
    "        print(f\"   Base URL: {api_config.base_url}\")\n",
    "        print(f\"   Test query: '{test_query}'\")\n",
    "        print(f\"   Returned {len(predictions)} predictions:\")\n",
    "        \n",
    "        for i, (skill, score) in enumerate(predictions[:3], 1):\n",
    "            print(f\"   {i}. {skill} (score: {score:.4f})\")\n",
    "        \n",
    "        if len(predictions) > 3:\n",
    "            print(f\"   ... and {len(predictions) - 3} more\")\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"â API '{api_config.name}' failed connectivity test:\")\n",
    "        print(f\"   Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Test connectivity for all configured APIs\n",
    "print(\"Testing API connectivity...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "api_test_results = {}\n",
    "for api_name, api_config in API_CONFIGS.items():\n",
    "    print(f\"\\nTesting {api_name}:\")\n",
    "    api_test_results[api_name] = test_api_connectivity(api_config)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"API Connectivity Summary:\")\n",
    "for api_name, is_working in api_test_results.items():\n",
    "    status = \"â Working\" if is_working else \"â Failed\"\n",
    "    print(f\"  {api_name}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run API evaluations\n",
    "# Only run evaluations for APIs that passed connectivity tests\n",
    "for api_name, api_config in API_CONFIGS.items():\n",
    "    if api_name in modelresults:\n",
    "        print(f\"Skipping {api_name} - already evaluated\")\n",
    "        continue\n",
    "    print(f\"\\nð Starting evaluation for {api_name}...\")\n",
    "    try:\n",
    "        modelresults[api_name] = evaluator(api_config=api_config)\n",
    "        print(f\"â Completed evaluation for {api_name}\")\n",
    "    except Exception as e:\n",
    "        # Print error and stack trace\n",
    "        print(f\"â Evaluation failed for {api_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        modelresults[api_name] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results to a file or merge with existing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Read the existing data\n",
    "existingresults = {}\n",
    "if os.path.exists(resultsfile):\n",
    "    with open(resultsfile, 'r', encoding='utf-8') as fIn:\n",
    "        existingresults = json.load(fIn)\n",
    "# Merge the two dictionaries\n",
    "for model, results in modelresults.items():\n",
    "    existingresults[model] = results\n",
    "\n",
    "# Write the new dictionary back to the file\n",
    "with open(resultsfile, 'w', encoding='utf-8') as fOut:\n",
    "    json.dump(existingresults, fOut, indent=4)\n",
    "\n",
    "modelresults = existingresults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the results as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1600d_row0_col1, #T_1600d_row0_col2, #T_1600d_row0_col3, #T_1600d_row0_col4, #T_1600d_row0_col5, #T_1600d_row0_col6, #T_1600d_row0_col7, #T_1600d_row0_col8, #T_1600d_row0_col9, #T_1600d_row0_col10, #T_1600d_row0_col11, #T_1600d_row0_col12, #T_1600d_row0_col13, #T_1600d_row0_col14, #T_1600d_row0_col15, #T_1600d_row4_col16 {\n",
       "  background-color: rgb(202,228,187);\n",
       "}\n",
       "#T_1600d_row0_col16, #T_1600d_row1_col1, #T_1600d_row1_col5, #T_1600d_row2_col2, #T_1600d_row2_col3, #T_1600d_row2_col4, #T_1600d_row2_col6, #T_1600d_row2_col7, #T_1600d_row2_col8, #T_1600d_row2_col10, #T_1600d_row2_col11, #T_1600d_row2_col12, #T_1600d_row2_col13, #T_1600d_row2_col15, #T_1600d_row3_col9, #T_1600d_row3_col14 {\n",
       "  background-color: rgb(110, 235, 55);\n",
       "}\n",
       "#T_1600d_row1_col2, #T_1600d_row1_col6, #T_1600d_row1_col7, #T_1600d_row1_col8, #T_1600d_row1_col11, #T_1600d_row1_col12, #T_1600d_row1_col13, #T_1600d_row1_col14, #T_1600d_row2_col1, #T_1600d_row2_col5, #T_1600d_row2_col9, #T_1600d_row2_col16, #T_1600d_row3_col3, #T_1600d_row3_col4, #T_1600d_row3_col10, #T_1600d_row3_col15 {\n",
       "  background-color: rgb(175,227,145);\n",
       "}\n",
       "#T_1600d_row1_col3, #T_1600d_row1_col4, #T_1600d_row1_col9, #T_1600d_row1_col10, #T_1600d_row1_col15, #T_1600d_row1_col16, #T_1600d_row2_col14, #T_1600d_row3_col1, #T_1600d_row3_col2, #T_1600d_row3_col5, #T_1600d_row3_col6, #T_1600d_row3_col7, #T_1600d_row3_col8, #T_1600d_row3_col11, #T_1600d_row3_col12, #T_1600d_row3_col13 {\n",
       "  background-color: rgb(147,226,102);\n",
       "}\n",
       "#T_1600d_row3_col16, #T_1600d_row4_col1, #T_1600d_row4_col2, #T_1600d_row4_col3, #T_1600d_row4_col4, #T_1600d_row4_col5, #T_1600d_row4_col6, #T_1600d_row4_col7, #T_1600d_row4_col8, #T_1600d_row4_col9, #T_1600d_row4_col10, #T_1600d_row4_col11, #T_1600d_row4_col12, #T_1600d_row4_col13, #T_1600d_row4_col14, #T_1600d_row4_col15 {\n",
       "  background-color: rgb(230,230,230);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1600d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1600d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_1600d_level0_col1\" class=\"col_heading level0 col1\" >accuracy@1</th>\n",
       "      <th id=\"T_1600d_level0_col2\" class=\"col_heading level0 col2\" >accuracy@3</th>\n",
       "      <th id=\"T_1600d_level0_col3\" class=\"col_heading level0 col3\" >accuracy@5</th>\n",
       "      <th id=\"T_1600d_level0_col4\" class=\"col_heading level0 col4\" >accuracy@10</th>\n",
       "      <th id=\"T_1600d_level0_col5\" class=\"col_heading level0 col5\" >precision@1</th>\n",
       "      <th id=\"T_1600d_level0_col6\" class=\"col_heading level0 col6\" >precision@3</th>\n",
       "      <th id=\"T_1600d_level0_col7\" class=\"col_heading level0 col7\" >precision@5</th>\n",
       "      <th id=\"T_1600d_level0_col8\" class=\"col_heading level0 col8\" >precision@10</th>\n",
       "      <th id=\"T_1600d_level0_col9\" class=\"col_heading level0 col9\" >recall@1</th>\n",
       "      <th id=\"T_1600d_level0_col10\" class=\"col_heading level0 col10\" >recall@3</th>\n",
       "      <th id=\"T_1600d_level0_col11\" class=\"col_heading level0 col11\" >recall@5</th>\n",
       "      <th id=\"T_1600d_level0_col12\" class=\"col_heading level0 col12\" >recall@10</th>\n",
       "      <th id=\"T_1600d_level0_col13\" class=\"col_heading level0 col13\" >ndcg@10</th>\n",
       "      <th id=\"T_1600d_level0_col14\" class=\"col_heading level0 col14\" >mrr@10</th>\n",
       "      <th id=\"T_1600d_level0_col15\" class=\"col_heading level0 col15\" >map@100</th>\n",
       "      <th id=\"T_1600d_level0_col16\" class=\"col_heading level0 col16\" >avg_time_per_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1600d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1600d_row0_col0\" class=\"data row0 col0\" >all-MiniLM-L6-v2</td>\n",
       "      <td id=\"T_1600d_row0_col1\" class=\"data row0 col1\" >0.231579</td>\n",
       "      <td id=\"T_1600d_row0_col2\" class=\"data row0 col2\" >0.378947</td>\n",
       "      <td id=\"T_1600d_row0_col3\" class=\"data row0 col3\" >0.442105</td>\n",
       "      <td id=\"T_1600d_row0_col4\" class=\"data row0 col4\" >0.505263</td>\n",
       "      <td id=\"T_1600d_row0_col5\" class=\"data row0 col5\" >0.231579</td>\n",
       "      <td id=\"T_1600d_row0_col6\" class=\"data row0 col6\" >0.147368</td>\n",
       "      <td id=\"T_1600d_row0_col7\" class=\"data row0 col7\" >0.115789</td>\n",
       "      <td id=\"T_1600d_row0_col8\" class=\"data row0 col8\" >0.089474</td>\n",
       "      <td id=\"T_1600d_row0_col9\" class=\"data row0 col9\" >0.038512</td>\n",
       "      <td id=\"T_1600d_row0_col10\" class=\"data row0 col10\" >0.064895</td>\n",
       "      <td id=\"T_1600d_row0_col11\" class=\"data row0 col11\" >0.084537</td>\n",
       "      <td id=\"T_1600d_row0_col12\" class=\"data row0 col12\" >0.121143</td>\n",
       "      <td id=\"T_1600d_row0_col13\" class=\"data row0 col13\" >0.144456</td>\n",
       "      <td id=\"T_1600d_row0_col14\" class=\"data row0 col14\" >0.322439</td>\n",
       "      <td id=\"T_1600d_row0_col15\" class=\"data row0 col15\" >0.087475</td>\n",
       "      <td id=\"T_1600d_row0_col16\" class=\"data row0 col16\" >0.045426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1600d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1600d_row1_col0\" class=\"data row1 col0\" >isy-finetuned</td>\n",
       "      <td id=\"T_1600d_row1_col1\" class=\"data row1 col1\" >0.631579</td>\n",
       "      <td id=\"T_1600d_row1_col2\" class=\"data row1 col2\" >0.821053</td>\n",
       "      <td id=\"T_1600d_row1_col3\" class=\"data row1 col3\" >0.884211</td>\n",
       "      <td id=\"T_1600d_row1_col4\" class=\"data row1 col4\" >0.957895</td>\n",
       "      <td id=\"T_1600d_row1_col5\" class=\"data row1 col5\" >0.631579</td>\n",
       "      <td id=\"T_1600d_row1_col6\" class=\"data row1 col6\" >0.508772</td>\n",
       "      <td id=\"T_1600d_row1_col7\" class=\"data row1 col7\" >0.444211</td>\n",
       "      <td id=\"T_1600d_row1_col8\" class=\"data row1 col8\" >0.340000</td>\n",
       "      <td id=\"T_1600d_row1_col9\" class=\"data row1 col9\" >0.099548</td>\n",
       "      <td id=\"T_1600d_row1_col10\" class=\"data row1 col10\" >0.234268</td>\n",
       "      <td id=\"T_1600d_row1_col11\" class=\"data row1 col11\" >0.316070</td>\n",
       "      <td id=\"T_1600d_row1_col12\" class=\"data row1 col12\" >0.448957</td>\n",
       "      <td id=\"T_1600d_row1_col13\" class=\"data row1 col13\" >0.496912</td>\n",
       "      <td id=\"T_1600d_row1_col14\" class=\"data row1 col14\" >0.736867</td>\n",
       "      <td id=\"T_1600d_row1_col15\" class=\"data row1 col15\" >0.394785</td>\n",
       "      <td id=\"T_1600d_row1_col16\" class=\"data row1 col16\" >0.330227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1600d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1600d_row2_col0\" class=\"data row2 col0\" >isy-finetuned-w-reranker</td>\n",
       "      <td id=\"T_1600d_row2_col1\" class=\"data row2 col1\" >0.600000</td>\n",
       "      <td id=\"T_1600d_row2_col2\" class=\"data row2 col2\" >0.863158</td>\n",
       "      <td id=\"T_1600d_row2_col3\" class=\"data row2 col3\" >0.936842</td>\n",
       "      <td id=\"T_1600d_row2_col4\" class=\"data row2 col4\" >0.989474</td>\n",
       "      <td id=\"T_1600d_row2_col5\" class=\"data row2 col5\" >0.600000</td>\n",
       "      <td id=\"T_1600d_row2_col6\" class=\"data row2 col6\" >0.533333</td>\n",
       "      <td id=\"T_1600d_row2_col7\" class=\"data row2 col7\" >0.492632</td>\n",
       "      <td id=\"T_1600d_row2_col8\" class=\"data row2 col8\" >0.380000</td>\n",
       "      <td id=\"T_1600d_row2_col9\" class=\"data row2 col9\" >0.091487</td>\n",
       "      <td id=\"T_1600d_row2_col10\" class=\"data row2 col10\" >0.247821</td>\n",
       "      <td id=\"T_1600d_row2_col11\" class=\"data row2 col11\" >0.357789</td>\n",
       "      <td id=\"T_1600d_row2_col12\" class=\"data row2 col12\" >0.511000</td>\n",
       "      <td id=\"T_1600d_row2_col13\" class=\"data row2 col13\" >0.534679</td>\n",
       "      <td id=\"T_1600d_row2_col14\" class=\"data row2 col14\" >0.738567</td>\n",
       "      <td id=\"T_1600d_row2_col15\" class=\"data row2 col15\" >0.418826</td>\n",
       "      <td id=\"T_1600d_row2_col16\" class=\"data row2 col16\" >8.157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1600d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1600d_row3_col0\" class=\"data row3 col0\" >competence_analyser</td>\n",
       "      <td id=\"T_1600d_row3_col1\" class=\"data row3 col1\" >0.631579</td>\n",
       "      <td id=\"T_1600d_row3_col2\" class=\"data row3 col2\" >0.842105</td>\n",
       "      <td id=\"T_1600d_row3_col3\" class=\"data row3 col3\" >0.884211</td>\n",
       "      <td id=\"T_1600d_row3_col4\" class=\"data row3 col4\" >0.915789</td>\n",
       "      <td id=\"T_1600d_row3_col5\" class=\"data row3 col5\" >0.631579</td>\n",
       "      <td id=\"T_1600d_row3_col6\" class=\"data row3 col6\" >0.515789</td>\n",
       "      <td id=\"T_1600d_row3_col7\" class=\"data row3 col7\" >0.492632</td>\n",
       "      <td id=\"T_1600d_row3_col8\" class=\"data row3 col8\" >0.372632</td>\n",
       "      <td id=\"T_1600d_row3_col9\" class=\"data row3 col9\" >0.102878</td>\n",
       "      <td id=\"T_1600d_row3_col10\" class=\"data row3 col10\" >0.227689</td>\n",
       "      <td id=\"T_1600d_row3_col11\" class=\"data row3 col11\" >0.338640</td>\n",
       "      <td id=\"T_1600d_row3_col12\" class=\"data row3 col12\" >0.476424</td>\n",
       "      <td id=\"T_1600d_row3_col13\" class=\"data row3 col13\" >0.526290</td>\n",
       "      <td id=\"T_1600d_row3_col14\" class=\"data row3 col14\" >0.746930</td>\n",
       "      <td id=\"T_1600d_row3_col15\" class=\"data row3 col15\" >0.391804</td>\n",
       "      <td id=\"T_1600d_row3_col16\" class=\"data row3 col16\" >10.064876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1600d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1600d_row4_col0\" class=\"data row4 col0\" >metadata_gen</td>\n",
       "      <td id=\"T_1600d_row4_col1\" class=\"data row4 col1\" >0.094737</td>\n",
       "      <td id=\"T_1600d_row4_col2\" class=\"data row4 col2\" >0.168421</td>\n",
       "      <td id=\"T_1600d_row4_col3\" class=\"data row4 col3\" >0.200000</td>\n",
       "      <td id=\"T_1600d_row4_col4\" class=\"data row4 col4\" >0.242105</td>\n",
       "      <td id=\"T_1600d_row4_col5\" class=\"data row4 col5\" >0.094737</td>\n",
       "      <td id=\"T_1600d_row4_col6\" class=\"data row4 col6\" >0.063158</td>\n",
       "      <td id=\"T_1600d_row4_col7\" class=\"data row4 col7\" >0.048421</td>\n",
       "      <td id=\"T_1600d_row4_col8\" class=\"data row4 col8\" >0.038947</td>\n",
       "      <td id=\"T_1600d_row4_col9\" class=\"data row4 col9\" >0.027206</td>\n",
       "      <td id=\"T_1600d_row4_col10\" class=\"data row4 col10\" >0.045882</td>\n",
       "      <td id=\"T_1600d_row4_col11\" class=\"data row4 col11\" >0.056759</td>\n",
       "      <td id=\"T_1600d_row4_col12\" class=\"data row4 col12\" >0.071716</td>\n",
       "      <td id=\"T_1600d_row4_col13\" class=\"data row4 col13\" >0.078389</td>\n",
       "      <td id=\"T_1600d_row4_col14\" class=\"data row4 col14\" >0.143317</td>\n",
       "      <td id=\"T_1600d_row4_col15\" class=\"data row4 col15\" >0.051326</td>\n",
       "      <td id=\"T_1600d_row4_col16\" class=\"data row4 col16\" >9.067596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28e51b5a350>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare results as a table\n",
    "import pandas as pd\n",
    "\n",
    "# compare results as a table\n",
    "import pandas as pd\n",
    "\n",
    "def get_result_df(modelresults):\n",
    "    results = pd.DataFrame({\n",
    "        'Model': list(modelresults.keys()),\n",
    "        'accuracy@1': [modelresults[model]['accuracy@1'] for model in modelresults],\n",
    "        'accuracy@3': [modelresults[model]['accuracy@3'] for model in modelresults],\n",
    "        'accuracy@5': [modelresults[model]['accuracy@5'] for model in modelresults],\n",
    "        'accuracy@10': [modelresults[model]['accuracy@10'] for model in modelresults],\n",
    "        'precision@1': [modelresults[model]['precision@1'] for model in modelresults],\n",
    "        'precision@3': [modelresults[model]['precision@3'] for model in modelresults],\n",
    "        'precision@5': [modelresults[model]['precision@5'] for model in modelresults],\n",
    "        'precision@10': [modelresults[model]['precision@10'] for model in modelresults],\n",
    "        'recall@1': [modelresults[model]['recall@1'] for model in modelresults],\n",
    "        'recall@3': [modelresults[model]['recall@3'] for model in modelresults],\n",
    "        'recall@5': [modelresults[model]['recall@5'] for model in modelresults],\n",
    "        'recall@10': [modelresults[model]['recall@10'] for model in modelresults],\n",
    "        'ndcg@10': [modelresults[model]['ndcg@10'] for model in modelresults],\n",
    "        'mrr@10': [modelresults[model]['mrr@10'] for model in modelresults],\n",
    "        'map@100': [modelresults[model]['map@100'] for model in modelresults],\n",
    "        # 'avg_time_per_1000_chars': [modelresults[model]['avg_time_per_1000_chars'] for model in modelresults],\n",
    "        'avg_time_per_query': [modelresults[model]['avg_time_per_query'] for model in modelresults],\n",
    "        # 'total_time': [modelresults[model]['total_time'] for model in modelresults]\n",
    "    })\n",
    "    return results\n",
    "\n",
    "# Filter modelresults for these modelnames in that order\n",
    "filtered_results = modelresults\n",
    "# filter_models = ['instructor-base', 'instructor-large', 'instructor-skillfit', 'bge_base', 'bge_greta_finetuned', 'bge_finetuned', 'bge_m3', 'bge_m3_greta_finetuned', 'bge_m3_finetuned', 'multilingual-e5-base', 'multilingual_e5_greta_finetuned', 'multilingual_e5_finetuned', 'mle5f+bge_reranker_skillfit', 'mle5f+bge_reranker_greta_finetuned', 'mle5f+bge_reranker_finetuned']\n",
    "# filter_models = ['intfloat/multilingual-e5-base', 'isy-thl/multilingual-e5-base-course-skill-tuned', 'isy-thl/bge-reranker-base-course-skill-tuned']\n",
    "# filtered_results = {model: modelresults[model] for model in filter_models}\n",
    "results = get_result_df(filtered_results)\n",
    "\n",
    "# filter_models = ['instructor-base', 'instructor-large', 'instructor-skillfit', 'bge_base', 'bge_greta_finetuned', 'bge_finetuned', 'bge_m3', 'bge_m3_greta_finetuned', 'bge_m3_finetuned', 'multilingual-e5-base', 'multilingual_e5_greta_finetuned', 'multilingual_e5_finetuned', 'bge_reranker_skillfit', 'bge_reranker_greta_finetuned', 'bge_reranker_finetuned']\n",
    "\n",
    "\n",
    "# def highlight_max(s):\n",
    "#     '''\n",
    "#     Highlight the maximum in a Series yellow.\n",
    "#     '''\n",
    "#     is_max = s == s.max()\n",
    "#     return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "def grade_by_rank(s):\n",
    "    # skip if column Model\n",
    "    if s.name == 'Model':\n",
    "        return ['' for v in s]\n",
    "    # Get count of values\n",
    "    count = len(s)\n",
    "    reverse = False\n",
    "    if 'time' in s.name:\n",
    "        reverse = True\n",
    "    ordered = s.sort_values(ascending=reverse)\n",
    "    # Define a lighter green RGB\n",
    "    good = (120, 225, 60)\n",
    "    # Define a grey RGB\n",
    "    bad = (230, 230, 230)\n",
    "    colors = []\n",
    "    if count == 1:\n",
    "        # If there is only one value, color it grey\n",
    "        colors.append('background-color: rgb(230,230,230)')\n",
    "    else:\n",
    "        for i, v in enumerate(ordered):\n",
    "            # Linear interpolation (lerp) between red and light green\n",
    "            r = int(good[0] + (bad[0] - good[0]) * (i / (count - 1)))\n",
    "            g = int(good[1] + (bad[1] - good[1]) * (i / (count - 1)))\n",
    "            b = int(good[2] + (bad[2] - good[2]) * (i / (count - 1)))\n",
    "            colors.append(f'background-color: rgb({r},{g},{b})')\n",
    "    \n",
    "    # Make best color even more vibrant\n",
    "    colors[0] = 'background-color: rgb(110, 235, 55)'\n",
    "    \n",
    "    # Assign colors to the original values based on their rank\n",
    "    styles = [colors[ordered.index.get_loc(i)] for i in s.index]\n",
    "    return styles\n",
    "\n",
    "\n",
    "# Apply the function along the DataFrame's columns\n",
    "styled_results = results.style.apply(grade_by_rank, axis=0)\n",
    "        \n",
    "styled_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
